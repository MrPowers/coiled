{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009581df",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "This notebook demonstrates how to benchmark basic computations with Dask in the Coiled execution environment.\n",
    "\n",
    "In a distributed environment, the same computation can have different runtimes, depending on the size of the cluster, partitioning of the data, computational parallelism, and other factors.\n",
    "\n",
    "Here are the main things you'll learn from the benchmarking in this notebook:\n",
    "\n",
    "* Dask is a lot faster when data is spread across multiple partitions so the computations can be run in parallel\n",
    "* Persisting DataFrames in memory can be a great performance optimization\n",
    "* Figuring out the optimal partitioning for a given computation is challenging\n",
    "* Lazy execution makes benchmarking challenging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c06eb",
   "metadata": {},
   "source": [
    "### Setup Coiled cluster to access Dask computation environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "66bfbe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled\n",
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "66f688fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = coiled.Cluster(name=\"benchmarking\", n_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc4ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e7046",
   "metadata": {},
   "source": [
    "## Count benchmarking\n",
    "\n",
    "This section reads a month of the NYC taxi data into different Dask DataFrames, performs a count, and measures computation time.  Here are the scenarios examined:\n",
    "\n",
    "1. Persisted DataFrame with 41 partitions\n",
    "2. Unpersisted DataFrame with 41 partitions\n",
    "3. Unpersisted DataFrame with 11 partitions\n",
    "4. Unpersisted DataFrame with 1 partition\n",
    "\n",
    "DataFrames with multiple partitions can perform count computations in parallel and that's why they're much faster!  Let's quantify the speed gains Dask provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07741b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    \"payment_type\": \"UInt8\",\n",
    "    \"VendorID\": \"UInt8\",\n",
    "    \"passenger_count\": \"UInt8\",\n",
    "    \"RatecodeID\": \"UInt8\",\n",
    "    \"store_and_fwd_flag\": \"category\",\n",
    "    \"PULocationID\": \"UInt16\",\n",
    "    \"DOLocationID\": \"UInt16\",\n",
    "}\n",
    "path = \"s3://nyc-tlc/trip data/yellow_tripdata_2019-01.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7164000f",
   "metadata": {},
   "source": [
    "### Create Persisted DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959b38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2019-01.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    dtype=dtype,\n",
    "    storage_options={\"anon\": True},\n",
    "    blocksize=\"16 MiB\",\n",
    ").persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0915f60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d33942",
   "metadata": {},
   "source": [
    "### Create unpersisted DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b13e107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unpersisted = dd.read_csv(\n",
    "    path,\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    dtype=dtype,\n",
    "    storage_options={\"anon\": True},\n",
    "    blocksize=\"16 MiB\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e0c0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unpersisted.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969fc908",
   "metadata": {},
   "source": [
    "### Create unpersisted DataFrame without setting blocksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eced95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_blocksize = dd.read_csv(\n",
    "    path,\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    dtype=dtype,\n",
    "    storage_options={\"anon\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09d8a134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_blocksize.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb0a8cf",
   "metadata": {},
   "source": [
    "### Create unpersisted DataFrame with blocksize set to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f75ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_none_blocksize = dd.read_csv(\n",
    "    path,\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    dtype=dtype,\n",
    "    storage_options={\"anon\": True},\n",
    "    blocksize=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66f233a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_none_blocksize.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78b5d84",
   "metadata": {},
   "source": [
    "### Define some benchmark helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2abd89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_benchmarks = {\n",
    "    'duration': [],  # in seconds\n",
    "    'task': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad88bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(f, df, benchmarks, name, **kwargs):\n",
    "    start_time = time.time()\n",
    "    ret = f(df, **kwargs)\n",
    "    benchmarks['duration'].append(time.time() - start_time)\n",
    "    benchmarks['task'].append(name)\n",
    "    print(f\"{name} took: {benchmarks['duration'][-1]} seconds\")\n",
    "    return benchmarks['duration'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d704025",
   "metadata": {},
   "source": [
    "### Run the count benchmarks with the different DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69efe96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(df):\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c89ab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_persisted took: 0.13576006889343262 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13576006889343262"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(count, df=df, benchmarks=dask_benchmarks, name='count_persisted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1135e10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_unpersisted took: 5.159780263900757 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.159780263900757"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(count, df=df_unpersisted, benchmarks=dask_benchmarks, name='count_unpersisted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95f7b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_no_blocksize took: 6.059859991073608 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.059859991073608"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(count, df=df_no_blocksize, benchmarks=dask_benchmarks, name='count_no_blocksize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f6f562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_none_blocksize took: 36.718952894210815 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36.718952894210815"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(count, df=df_none_blocksize, benchmarks=dask_benchmarks, name='count_none_blocksize')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da3f340",
   "metadata": {},
   "source": [
    "## Count benchmarking conclusions\n",
    "\n",
    "Running the count operation on a persisted DataFrame with 41 partitions is by far the fastest.  The operation is much slower when the DataFrame isn't persisted and when fewer partitions are used.  Using one partition is particularily slow because it prohibits Dask from performing the computation in parallel.\n",
    "\n",
    "Count benchmarks are OK for CSV files, but should be avoided when benmarking data stored in the Parquet file format.  Parquet files store count metadata in the file footer.  Execution engines can just grab the count from the file footer rather than reading in all the data and actually performing the count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a549dc9",
   "metadata": {},
   "source": [
    "## mean benchmarking\n",
    "\n",
    "Let's calculate the mean fare using the same DataFrames as above and see if the computation time results are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a3e8640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(df):\n",
    "    return df.fare_amount.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de1ae12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_persisted took: 0.1818859577178955 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1818859577178955"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(mean, df=df, benchmarks=dask_benchmarks, name='mean_persisted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1e2de96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_unpersisted took: 5.212815046310425 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.212815046310425"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(mean, df=df_unpersisted, benchmarks=dask_benchmarks, name='mean_unpersisted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8da3a079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_no_blocksize took: 6.081754922866821 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.081754922866821"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(mean, df=df_no_blocksize, benchmarks=dask_benchmarks, name='mean_no_blocksize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6eaafcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_none_blocksize took: 34.238887786865234 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34.238887786865234"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(mean, df=df_none_blocksize, benchmarks=dask_benchmarks, name='mean_none_blocksize')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de11a591",
   "metadata": {},
   "source": [
    "## Mean benchmarking conclusions\n",
    "\n",
    "The mean benchmarks unsurprisingly show the same results as the count benchmarks.  DataFrames with more partitions that are persisted in memory are a lot faster.  Count and mean operations are easy to parallelize on a cluster.  Let's turn our attention to an aggregation that's more complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40f257",
   "metadata": {},
   "source": [
    "## Group by benchmarking\n",
    "\n",
    "Let's compute the total fare amount, by day.  Remember that the data is distributed in 41 different partitions spread across different nodes in the cluster.  Data for a given day may be spread across each memory partition.\n",
    "\n",
    "Certain aggregataions require the data to be shuffled, which can be expensive.  Minimizing data shuffling is one of the best performance optimizations in a cluster environment.\n",
    "\n",
    "This section will calculate a sum, which is easier to parallelize than other aggregations, like a distinct count.  Let's view the output of this computation before running the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "442b2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unpersisted[\"pickup_day\"] = df_unpersisted[\"tpep_pickup_datetime\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9c34766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_day\n",
       "2019-01-11    4213545.05\n",
       "2019-01-25    3629449.04\n",
       "2019-01-23    3625535.48\n",
       "2019-01-17    3547486.80\n",
       "2019-01-24    3521669.99\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unpersisted.groupby(\"pickup_day\").fare_amount.sum().compute().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9591e8c8",
   "metadata": {},
   "source": [
    "## Benchmark the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "179d9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_benchmark(f):\n",
    "  start_time = time.time()\n",
    "  f()\n",
    "  return time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9e824b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0322792530059814"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_benchmark(lambda: df_unpersisted.groupby('pickup_day').fare_amount.sum().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312d6c29",
   "metadata": {},
   "source": [
    "## Set an index and see if that makes the computation run faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01044720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unpersisted2 = df_unpersisted.set_index(\"pickup_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91e055a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.970112085342407"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_benchmark(lambda: df_unpersisted2.groupby('pickup_day').fare_amount.sum().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319eb2b",
   "metadata": {},
   "source": [
    "In this case the cost of setting the index outweighs the performance benefit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc66f68",
   "metadata": {},
   "source": [
    "## Closing thoughts\n",
    "\n",
    "This benchmarking analysis demonstrates the power of cluster computing with Dask.  It also highlights the unique challenges of working in a cluster environment.  Organizing data in the right memory partitions and strategically executing computations is necessary to optimize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebe6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
